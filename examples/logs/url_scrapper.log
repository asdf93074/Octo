07/16/2024 01:44:50 AM -- INFO  --  crawler.py:103 -- Starting URL scrapper.
07/16/2024 01:44:50 AM -- INFO  --  crawler.py:106 -- Fetching new URL from redis.
07/16/2024 01:44:50 AM -- ERROR  --  crawler.py:124 -- Error while processing URL: None, error: name '_get_next_url_from_datasource' is not defined
07/16/2024 01:45:02 AM -- ERROR  --  crawler.py:124 -- Error while processing URL: None, error: name '_get_next_url_from_datasource' is not defined
07/16/2024 01:45:14 AM -- ERROR  --  crawler.py:124 -- Error while processing URL: None, error: name '_get_next_url_from_datasource' is not defined
07/16/2024 01:45:24 AM -- ERROR  --  crawler.py:124 -- Error while processing URL: None, error: name '_get_next_url_from_datasource' is not defined
07/16/2024 01:45:35 AM -- INFO  --  crawler.py:103 -- Starting URL scrapper.
07/16/2024 01:45:35 AM -- INFO  --  crawler.py:106 -- Fetching new URL from redis.
07/16/2024 01:45:35 AM -- ERROR  --  crawler.py:124 -- Error while processing URL: https://www.goodreads.com/book/show/30300392-catastrophe, error: name 'process_url' is not defined
07/16/2024 01:45:44 AM -- ERROR  --  crawler.py:124 -- Error while processing URL: https://www.goodreads.com/book/show/66518.Children_of_the_Storm, error: name 'process_url' is not defined
07/16/2024 01:45:52 AM -- ERROR  --  crawler.py:124 -- Error while processing URL: https://www.goodreads.com/book/show/19192630-divergent-parody, error: name 'process_url' is not defined
07/16/2024 01:46:07 AM -- ERROR  --  crawler.py:124 -- Error while processing URL: https://www.goodreads.com/book/show/98573.Harold_and_the_Purple_Crayon, error: name 'process_url' is not defined
07/16/2024 01:46:18 AM -- INFO  --  crawler.py:103 -- Starting URL scrapper.
07/16/2024 01:46:18 AM -- INFO  --  crawler.py:106 -- Fetching new URL from redis.
07/16/2024 01:46:18 AM -- INFO  --  crawler.py:122 -- Queued processing for URL: https://www.goodreads.com/book/show/11012.Dubliners.
07/16/2024 01:46:31 AM -- ERROR  --  base_events.py:1821 -- Task exception was never retrieved
future: <Task finished name='Task-11012.Dubliners' coro=<Crawler.process_url() done, defined at /home/mk/code/goodreads_crawler/src/octo/core/crawler.py:83> exception=KeyError('book_url')>
Traceback (most recent call last):
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 84, in process_url
    parse_response = await self._scrape(url)
                     ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 79, in _scrape
    parse_response = await self._parser.parse(self._browser, { "url": url } )
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/parser/parser.py", line 19, in parse
    context = await s.run(browser, context, pr)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/examples/main.py", line 37, in run
    book_url = context["book_url"]
               ~~~~~~~^^^^^^^^^^^^
KeyError: 'book_url'
07/16/2024 01:46:31 AM -- INFO  --  crawler.py:122 -- Queued processing for URL: https://www.goodreads.com/book/show/75495037-the-stranger-upstairs.
07/16/2024 01:46:44 AM -- ERROR  --  base_events.py:1821 -- Task exception was never retrieved
future: <Task finished name='Task-75495037-the-stranger-upstairs' coro=<Crawler.process_url() done, defined at /home/mk/code/goodreads_crawler/src/octo/core/crawler.py:83> exception=KeyError('book_url')>
Traceback (most recent call last):
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 84, in process_url
    parse_response = await self._scrape(url)
                     ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 79, in _scrape
    parse_response = await self._parser.parse(self._browser, { "url": url } )
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/parser/parser.py", line 19, in parse
    context = await s.run(browser, context, pr)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/examples/main.py", line 37, in run
    book_url = context["book_url"]
               ~~~~~~~^^^^^^^^^^^^
KeyError: 'book_url'
07/16/2024 01:46:44 AM -- INFO  --  crawler.py:122 -- Queued processing for URL: https://www.goodreads.com/book/show/348273.Under_the_Feet_of_Jesus.
07/16/2024 01:46:53 AM -- ERROR  --  base_events.py:1821 -- Task exception was never retrieved
future: <Task finished name='Task-348273.Under_the_Feet_of_Jesus' coro=<Crawler.process_url() done, defined at /home/mk/code/goodreads_crawler/src/octo/core/crawler.py:83> exception=KeyError('book_url')>
Traceback (most recent call last):
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 84, in process_url
    parse_response = await self._scrape(url)
                     ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 79, in _scrape
    parse_response = await self._parser.parse(self._browser, { "url": url } )
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/parser/parser.py", line 19, in parse
    context = await s.run(browser, context, pr)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/examples/main.py", line 37, in run
    book_url = context["book_url"]
               ~~~~~~~^^^^^^^^^^^^
KeyError: 'book_url'
07/16/2024 01:46:53 AM -- INFO  --  crawler.py:122 -- Queued processing for URL: https://www.goodreads.com/book/show/60877616-really-good-actually.
07/16/2024 01:47:03 AM -- ERROR  --  base_events.py:1821 -- Task exception was never retrieved
future: <Task finished name='Task-60877616-really-good-actually' coro=<Crawler.process_url() done, defined at /home/mk/code/goodreads_crawler/src/octo/core/crawler.py:83> exception=KeyError('book_url')>
Traceback (most recent call last):
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 84, in process_url
    parse_response = await self._scrape(url)
                     ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 79, in _scrape
    parse_response = await self._parser.parse(self._browser, { "url": url } )
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/parser/parser.py", line 19, in parse
    context = await s.run(browser, context, pr)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/examples/main.py", line 37, in run
    book_url = context["book_url"]
               ~~~~~~~^^^^^^^^^^^^
KeyError: 'book_url'
07/16/2024 01:47:03 AM -- INFO  --  crawler.py:122 -- Queued processing for URL: https://www.goodreads.com/book/show/16211529-behind-the-sun.
07/16/2024 01:47:16 AM -- ERROR  --  base_events.py:1821 -- Task exception was never retrieved
future: <Task finished name='Task-16211529-behind-the-sun' coro=<Crawler.process_url() done, defined at /home/mk/code/goodreads_crawler/src/octo/core/crawler.py:83> exception=KeyError('book_url')>
Traceback (most recent call last):
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 84, in process_url
    parse_response = await self._scrape(url)
                     ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 79, in _scrape
    parse_response = await self._parser.parse(self._browser, { "url": url } )
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/parser/parser.py", line 19, in parse
    context = await s.run(browser, context, pr)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/examples/main.py", line 37, in run
    book_url = context["book_url"]
               ~~~~~~~^^^^^^^^^^^^
KeyError: 'book_url'
07/16/2024 01:47:16 AM -- INFO  --  crawler.py:122 -- Queued processing for URL: https://www.goodreads.com/book/show/58269569-bloom-into-you-anthology-volume-one.
07/16/2024 01:47:27 AM -- ERROR  --  base_events.py:1821 -- Task exception was never retrieved
future: <Task finished name='Task-58269569-bloom-into-you-anthology-volume-one' coro=<Crawler.process_url() done, defined at /home/mk/code/goodreads_crawler/src/octo/core/crawler.py:83> exception=KeyError('book_url')>
Traceback (most recent call last):
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 84, in process_url
    parse_response = await self._scrape(url)
                     ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 79, in _scrape
    parse_response = await self._parser.parse(self._browser, { "url": url } )
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/parser/parser.py", line 19, in parse
    context = await s.run(browser, context, pr)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/examples/main.py", line 37, in run
    book_url = context["book_url"]
               ~~~~~~~^^^^^^^^^^^^
KeyError: 'book_url'
07/16/2024 01:47:27 AM -- INFO  --  crawler.py:122 -- Queued processing for URL: https://www.goodreads.com/book/show/228765.The_Zen_of_Seeing.
07/16/2024 01:47:40 AM -- ERROR  --  base_events.py:1821 -- Task exception was never retrieved
future: <Task finished name='Task-228765.The_Zen_of_Seeing' coro=<Crawler.process_url() done, defined at /home/mk/code/goodreads_crawler/src/octo/core/crawler.py:83> exception=KeyError('book_url')>
Traceback (most recent call last):
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 84, in process_url
    parse_response = await self._scrape(url)
                     ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 79, in _scrape
    parse_response = await self._parser.parse(self._browser, { "url": url } )
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/parser/parser.py", line 19, in parse
    context = await s.run(browser, context, pr)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/examples/main.py", line 37, in run
    book_url = context["book_url"]
               ~~~~~~~^^^^^^^^^^^^
KeyError: 'book_url'
07/16/2024 01:47:40 AM -- INFO  --  crawler.py:122 -- Queued processing for URL: https://www.goodreads.com/book/show/24874354-to-morrow.
07/16/2024 01:47:52 AM -- ERROR  --  base_events.py:1821 -- Task exception was never retrieved
future: <Task finished name='Task-24874354-to-morrow' coro=<Crawler.process_url() done, defined at /home/mk/code/goodreads_crawler/src/octo/core/crawler.py:83> exception=KeyError('book_url')>
Traceback (most recent call last):
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 84, in process_url
    parse_response = await self._scrape(url)
                     ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 79, in _scrape
    parse_response = await self._parser.parse(self._browser, { "url": url } )
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/parser/parser.py", line 19, in parse
    context = await s.run(browser, context, pr)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/examples/main.py", line 37, in run
    book_url = context["book_url"]
               ~~~~~~~^^^^^^^^^^^^
KeyError: 'book_url'
07/16/2024 01:47:52 AM -- INFO  --  crawler.py:122 -- Queued processing for URL: https://www.goodreads.com/book/show/62929342-real-americans.
07/16/2024 01:48:07 AM -- ERROR  --  base_events.py:1821 -- Task exception was never retrieved
future: <Task finished name='Task-62929342-real-americans' coro=<Crawler.process_url() done, defined at /home/mk/code/goodreads_crawler/src/octo/core/crawler.py:83> exception=KeyError('book_url')>
Traceback (most recent call last):
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 84, in process_url
    parse_response = await self._scrape(url)
                     ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 79, in _scrape
    parse_response = await self._parser.parse(self._browser, { "url": url } )
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/parser/parser.py", line 19, in parse
    context = await s.run(browser, context, pr)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/examples/main.py", line 37, in run
    book_url = context["book_url"]
               ~~~~~~~^^^^^^^^^^^^
KeyError: 'book_url'
07/16/2024 01:48:07 AM -- INFO  --  crawler.py:122 -- Queued processing for URL: https://www.goodreads.com/book/show/434271.Maybe_You_Should_Fly_a_Jet_Maybe_You_Should_Be_a_Vet_.
07/16/2024 01:48:15 AM -- ERROR  --  base_events.py:1821 -- Task exception was never retrieved
future: <Task finished name='Task-434271.Maybe_You_Should_Fly_a_Jet_Maybe_You_Should_Be_a_Vet_' coro=<Crawler.process_url() done, defined at /home/mk/code/goodreads_crawler/src/octo/core/crawler.py:83> exception=KeyError('book_url')>
Traceback (most recent call last):
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 84, in process_url
    parse_response = await self._scrape(url)
                     ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 79, in _scrape
    parse_response = await self._parser.parse(self._browser, { "url": url } )
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/parser/parser.py", line 19, in parse
    context = await s.run(browser, context, pr)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/examples/main.py", line 37, in run
    book_url = context["book_url"]
               ~~~~~~~^^^^^^^^^^^^
KeyError: 'book_url'
07/16/2024 01:48:15 AM -- INFO  --  crawler.py:122 -- Queued processing for URL: https://www.goodreads.com/book/show/181848975-the-whisperwicks.
07/16/2024 01:48:28 AM -- ERROR  --  base_events.py:1821 -- Task exception was never retrieved
future: <Task finished name='Task-181848975-the-whisperwicks' coro=<Crawler.process_url() done, defined at /home/mk/code/goodreads_crawler/src/octo/core/crawler.py:83> exception=KeyError('book_url')>
Traceback (most recent call last):
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 84, in process_url
    parse_response = await self._scrape(url)
                     ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 79, in _scrape
    parse_response = await self._parser.parse(self._browser, { "url": url } )
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/parser/parser.py", line 19, in parse
    context = await s.run(browser, context, pr)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/examples/main.py", line 37, in run
    book_url = context["book_url"]
               ~~~~~~~^^^^^^^^^^^^
KeyError: 'book_url'
07/16/2024 01:48:28 AM -- INFO  --  crawler.py:122 -- Queued processing for URL: https://www.goodreads.com/book/show/12833770-the-mystery-boxes.
07/16/2024 01:48:28 AM -- ERROR  --  base_events.py:1821 -- Task exception was never retrieved
future: <Task finished name='Task-12833770-the-mystery-boxes' coro=<Crawler.process_url() done, defined at /home/mk/code/goodreads_crawler/src/octo/core/crawler.py:83> exception=KeyError('book_url')>
Traceback (most recent call last):
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 84, in process_url
    parse_response = await self._scrape(url)
                     ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 79, in _scrape
    parse_response = await self._parser.parse(self._browser, { "url": url } )
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/parser/parser.py", line 19, in parse
    context = await s.run(browser, context, pr)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/examples/main.py", line 37, in run
    book_url = context["book_url"]
               ~~~~~~~^^^^^^^^^^^^
KeyError: 'book_url'
07/16/2024 01:51:27 AM -- INFO  --  crawler.py:103 -- Starting URL scrapper.
07/16/2024 01:51:27 AM -- INFO  --  crawler.py:106 -- Fetching new URL from redis.
07/16/2024 01:51:27 AM -- INFO  --  crawler.py:122 -- Queued processing for URL: https://www.goodreads.com/book/show/5.Harry_Potter_and_the_Prisoner_of_Azkaban.
07/16/2024 01:51:38 AM -- INFO  --  crawler.py:122 -- Queued processing for URL: https://www.goodreads.com/book/show/204898124-dalla-stessa-parte-mi-troverai.
07/16/2024 01:51:47 AM -- INFO  --  crawler.py:122 -- Queued processing for URL: https://www.goodreads.com/book/show/1335184.Walt_Disney_s_Peter_Pan.
07/16/2024 01:51:55 AM -- INFO  --  crawler.py:122 -- Queued processing for URL: https://www.goodreads.com/book/show/74951530-happiness.
07/16/2024 01:52:03 AM -- INFO  --  crawler.py:122 -- Queued processing for URL: https://www.goodreads.com/book/show/210654140-all-incrocio-dei-nostri-destini.
07/16/2024 01:52:03 AM -- ERROR  --  base_events.py:1821 -- Task exception was never retrieved
future: <Task finished name='Task-1335184.Walt_Disney_s_Peter_Pan' coro=<Crawler.process_url() done, defined at /home/mk/code/goodreads_crawler/src/octo/core/crawler.py:83> exception=TargetClosedError('Browser.new_page: Target page, context or browser has been closed')>
Traceback (most recent call last):
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 84, in process_url
    parse_response = await self._scrape(url)
                     ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 79, in _scrape
    parse_response = await self._parser.parse(self._browser, { "url": url } )
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/parser/parser.py", line 19, in parse
    context = await s.run(browser, context, pr)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/examples/main.py", line 38, in run
    page = await browser.new_page()
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/dev/lib/python3.12/site-packages/playwright/async_api/_generated.py", line 13834, in new_page
    await self._impl_obj.new_page(
  File "/home/mk/code/goodreads_crawler/dev/lib/python3.12/site-packages/playwright/_impl/_browser.py", line 178, in new_page
    return await self._connection.wrap_api_call(inner)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/dev/lib/python3.12/site-packages/playwright/_impl/_connection.py", line 514, in wrap_api_call
    raise rewrite_error(error, f"{parsed_st['apiName']}: {error}") from None
playwright._impl._errors.TargetClosedError: Browser.new_page: Target page, context or browser has been closed
07/16/2024 01:52:03 AM -- ERROR  --  base_events.py:1821 -- Task exception was never retrieved
future: <Task finished name='Task-74951530-happiness' coro=<Crawler.process_url() done, defined at /home/mk/code/goodreads_crawler/src/octo/core/crawler.py:83> exception=TargetClosedError('Browser.new_page: Target page, context or browser has been closed')>
Traceback (most recent call last):
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 84, in process_url
    parse_response = await self._scrape(url)
                     ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 79, in _scrape
    parse_response = await self._parser.parse(self._browser, { "url": url } )
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/parser/parser.py", line 19, in parse
    context = await s.run(browser, context, pr)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/examples/main.py", line 38, in run
    page = await browser.new_page()
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/dev/lib/python3.12/site-packages/playwright/async_api/_generated.py", line 13834, in new_page
    await self._impl_obj.new_page(
  File "/home/mk/code/goodreads_crawler/dev/lib/python3.12/site-packages/playwright/_impl/_browser.py", line 178, in new_page
    return await self._connection.wrap_api_call(inner)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/dev/lib/python3.12/site-packages/playwright/_impl/_connection.py", line 514, in wrap_api_call
    raise rewrite_error(error, f"{parsed_st['apiName']}: {error}") from None
playwright._impl._errors.TargetClosedError: Browser.new_page: Target page, context or browser has been closed
07/16/2024 01:52:17 AM -- INFO  --  crawler.py:122 -- Queued processing for URL: https://www.goodreads.com/book/show/63906868-hard-is-not-the-same-thing-as-bad.
07/16/2024 01:52:26 AM -- INFO  --  crawler.py:122 -- Queued processing for URL: https://www.goodreads.com/book/show/41746324-the-tradition.
07/16/2024 01:52:36 AM -- INFO  --  crawler.py:122 -- Queued processing for URL: https://www.goodreads.com/book/show/62049729-the-celebrants.
07/16/2024 01:52:48 AM -- INFO  --  crawler.py:122 -- Queued processing for URL: https://www.goodreads.com/book/show/29934.What_Work_Is.
07/16/2024 01:53:00 AM -- INFO  --  crawler.py:122 -- Queued processing for URL: https://www.goodreads.com/book/show/195820807-just-for-the-summer.
07/16/2024 01:53:00 AM -- ERROR  --  base_events.py:1821 -- Task exception was never retrieved
future: <Task finished name='Task-63906868-hard-is-not-the-same-thing-as-bad' coro=<Crawler.process_url() done, defined at /home/mk/code/goodreads_crawler/src/octo/core/crawler.py:83> exception=TargetClosedError('Browser.new_page: Target page, context or browser has been closed')>
Traceback (most recent call last):
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 84, in process_url
    parse_response = await self._scrape(url)
                     ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 79, in _scrape
    parse_response = await self._parser.parse(self._browser, { "url": url } )
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/parser/parser.py", line 19, in parse
    context = await s.run(browser, context, pr)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/examples/main.py", line 38, in run
    page = await browser.new_page()
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/dev/lib/python3.12/site-packages/playwright/async_api/_generated.py", line 13834, in new_page
    await self._impl_obj.new_page(
  File "/home/mk/code/goodreads_crawler/dev/lib/python3.12/site-packages/playwright/_impl/_browser.py", line 178, in new_page
    return await self._connection.wrap_api_call(inner)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/dev/lib/python3.12/site-packages/playwright/_impl/_connection.py", line 514, in wrap_api_call
    raise rewrite_error(error, f"{parsed_st['apiName']}: {error}") from None
playwright._impl._errors.TargetClosedError: Browser.new_page: Target page, context or browser has been closed
07/16/2024 01:53:00 AM -- ERROR  --  base_events.py:1821 -- Task exception was never retrieved
future: <Task finished name='Task-41746324-the-tradition' coro=<Crawler.process_url() done, defined at /home/mk/code/goodreads_crawler/src/octo/core/crawler.py:83> exception=TargetClosedError('Browser.new_page: Target page, context or browser has been closed')>
Traceback (most recent call last):
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 84, in process_url
    parse_response = await self._scrape(url)
                     ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 79, in _scrape
    parse_response = await self._parser.parse(self._browser, { "url": url } )
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/parser/parser.py", line 19, in parse
    context = await s.run(browser, context, pr)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/examples/main.py", line 38, in run
    page = await browser.new_page()
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/dev/lib/python3.12/site-packages/playwright/async_api/_generated.py", line 13834, in new_page
    await self._impl_obj.new_page(
  File "/home/mk/code/goodreads_crawler/dev/lib/python3.12/site-packages/playwright/_impl/_browser.py", line 178, in new_page
    return await self._connection.wrap_api_call(inner)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/dev/lib/python3.12/site-packages/playwright/_impl/_connection.py", line 514, in wrap_api_call
    raise rewrite_error(error, f"{parsed_st['apiName']}: {error}") from None
playwright._impl._errors.TargetClosedError: Browser.new_page: Target page, context or browser has been closed
07/16/2024 01:53:00 AM -- ERROR  --  base_events.py:1821 -- Task exception was never retrieved
future: <Task finished name='Task-62049729-the-celebrants' coro=<Crawler.process_url() done, defined at /home/mk/code/goodreads_crawler/src/octo/core/crawler.py:83> exception=TargetClosedError('Browser.new_page: Target page, context or browser has been closed')>
Traceback (most recent call last):
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 84, in process_url
    parse_response = await self._scrape(url)
                     ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 79, in _scrape
    parse_response = await self._parser.parse(self._browser, { "url": url } )
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/parser/parser.py", line 19, in parse
    context = await s.run(browser, context, pr)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/examples/main.py", line 38, in run
    page = await browser.new_page()
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/dev/lib/python3.12/site-packages/playwright/async_api/_generated.py", line 13834, in new_page
    await self._impl_obj.new_page(
  File "/home/mk/code/goodreads_crawler/dev/lib/python3.12/site-packages/playwright/_impl/_browser.py", line 178, in new_page
    return await self._connection.wrap_api_call(inner)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/dev/lib/python3.12/site-packages/playwright/_impl/_connection.py", line 514, in wrap_api_call
    raise rewrite_error(error, f"{parsed_st['apiName']}: {error}") from None
playwright._impl._errors.TargetClosedError: Browser.new_page: Target page, context or browser has been closed
07/16/2024 01:53:00 AM -- ERROR  --  base_events.py:1821 -- Task exception was never retrieved
future: <Task finished name='Task-29934.What_Work_Is' coro=<Crawler.process_url() done, defined at /home/mk/code/goodreads_crawler/src/octo/core/crawler.py:83> exception=TargetClosedError('Browser.new_page: Target page, context or browser has been closed')>
Traceback (most recent call last):
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 84, in process_url
    parse_response = await self._scrape(url)
                     ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 79, in _scrape
    parse_response = await self._parser.parse(self._browser, { "url": url } )
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/parser/parser.py", line 19, in parse
    context = await s.run(browser, context, pr)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/examples/main.py", line 38, in run
    page = await browser.new_page()
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/dev/lib/python3.12/site-packages/playwright/async_api/_generated.py", line 13834, in new_page
    await self._impl_obj.new_page(
  File "/home/mk/code/goodreads_crawler/dev/lib/python3.12/site-packages/playwright/_impl/_browser.py", line 178, in new_page
    return await self._connection.wrap_api_call(inner)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/dev/lib/python3.12/site-packages/playwright/_impl/_connection.py", line 514, in wrap_api_call
    raise rewrite_error(error, f"{parsed_st['apiName']}: {error}") from None
playwright._impl._errors.TargetClosedError: Browser.new_page: Target page, context or browser has been closed
07/16/2024 01:53:06 AM -- ERROR  --  base_events.py:1821 -- Task exception was never retrieved
future: <Task finished name='Task-204898124-dalla-stessa-parte-mi-troverai' coro=<Crawler.process_url() done, defined at /home/mk/code/goodreads_crawler/src/octo/core/crawler.py:83> exception=TargetClosedError('Page.wait_for_timeout: Target page, context or browser has been closed')>
Traceback (most recent call last):
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 84, in process_url
    parse_response = await self._scrape(url)
                     ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 79, in _scrape
    parse_response = await self._parser.parse(self._browser, { "url": url } )
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/parser/parser.py", line 19, in parse
    context = await s.run(browser, context, pr)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/examples/main.py", line 62, in run
    await page.wait_for_timeout(2000)
  File "/home/mk/code/goodreads_crawler/dev/lib/python3.12/site-packages/playwright/async_api/_generated.py", line 11174, in wait_for_timeout
    await self._impl_obj.wait_for_timeout(timeout=timeout)
  File "/home/mk/code/goodreads_crawler/dev/lib/python3.12/site-packages/playwright/_impl/_page.py", line 1023, in wait_for_timeout
    await self._main_frame.wait_for_timeout(timeout)
  File "/home/mk/code/goodreads_crawler/dev/lib/python3.12/site-packages/playwright/_impl/_frame.py", line 758, in wait_for_timeout
    await self._channel.send("waitForTimeout", locals_to_params(locals()))
  File "/home/mk/code/goodreads_crawler/dev/lib/python3.12/site-packages/playwright/_impl/_connection.py", line 59, in send
    return await self._connection.wrap_api_call(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/dev/lib/python3.12/site-packages/playwright/_impl/_connection.py", line 514, in wrap_api_call
    raise rewrite_error(error, f"{parsed_st['apiName']}: {error}") from None
playwright._impl._errors.TargetClosedError: Page.wait_for_timeout: Target page, context or browser has been closed
07/16/2024 01:53:06 AM -- ERROR  --  base_events.py:1821 -- Task exception was never retrieved
future: <Task finished name='Task-210654140-all-incrocio-dei-nostri-destini' coro=<Crawler.process_url() done, defined at /home/mk/code/goodreads_crawler/src/octo/core/crawler.py:83> exception=TargetClosedError('Browser.new_page: Target page, context or browser has been closed')>
Traceback (most recent call last):
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 84, in process_url
    parse_response = await self._scrape(url)
                     ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 79, in _scrape
    parse_response = await self._parser.parse(self._browser, { "url": url } )
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/parser/parser.py", line 19, in parse
    context = await s.run(browser, context, pr)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/examples/main.py", line 38, in run
    page = await browser.new_page()
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/dev/lib/python3.12/site-packages/playwright/async_api/_generated.py", line 13834, in new_page
    await self._impl_obj.new_page(
  File "/home/mk/code/goodreads_crawler/dev/lib/python3.12/site-packages/playwright/_impl/_browser.py", line 178, in new_page
    return await self._connection.wrap_api_call(inner)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/dev/lib/python3.12/site-packages/playwright/_impl/_connection.py", line 514, in wrap_api_call
    raise rewrite_error(error, f"{parsed_st['apiName']}: {error}") from None
playwright._impl._errors.TargetClosedError: Browser.new_page: Target page, context or browser has been closed
07/16/2024 01:53:06 AM -- ERROR  --  base_events.py:1821 -- Task exception was never retrieved
future: <Task finished name='Task-195820807-just-for-the-summer' coro=<Crawler.process_url() done, defined at /home/mk/code/goodreads_crawler/src/octo/core/crawler.py:83> exception=TargetClosedError('Browser.new_page: Target page, context or browser has been closed')>
Traceback (most recent call last):
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 84, in process_url
    parse_response = await self._scrape(url)
                     ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 79, in _scrape
    parse_response = await self._parser.parse(self._browser, { "url": url } )
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/parser/parser.py", line 19, in parse
    context = await s.run(browser, context, pr)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/examples/main.py", line 38, in run
    page = await browser.new_page()
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/dev/lib/python3.12/site-packages/playwright/async_api/_generated.py", line 13834, in new_page
    await self._impl_obj.new_page(
  File "/home/mk/code/goodreads_crawler/dev/lib/python3.12/site-packages/playwright/_impl/_browser.py", line 178, in new_page
    return await self._connection.wrap_api_call(inner)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/dev/lib/python3.12/site-packages/playwright/_impl/_connection.py", line 514, in wrap_api_call
    raise rewrite_error(error, f"{parsed_st['apiName']}: {error}") from None
playwright._impl._errors.TargetClosedError: Browser.new_page: Target page, context or browser has been closed
07/16/2024 01:55:47 AM -- INFO  --  crawler.py:103 -- Starting URL scrapper.
07/16/2024 01:55:47 AM -- INFO  --  crawler.py:106 -- Fetching new URL from redis.
07/16/2024 01:55:47 AM -- INFO  --  crawler.py:122 -- Queued processing for URL: https://www.goodreads.com/book/show/995793.The_Panda_Puzzle.
07/16/2024 01:55:58 AM -- INFO  --  crawler.py:122 -- Queued processing for URL: https://www.goodreads.com/book/show/57921696-poes-a-masculina.
07/16/2024 01:56:03 AM -- ERROR  --  base_events.py:1821 -- Task exception was never retrieved
future: <Task finished name='Task-57921696-poes-a-masculina' coro=<Crawler.process_url() done, defined at /home/mk/code/goodreads_crawler/src/octo/core/crawler.py:83> exception=TargetClosedError('Page.wait_for_timeout: Target page, context or browser has been closed')>
Traceback (most recent call last):
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 84, in process_url
    parse_response = await self._scrape(url)
                     ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 79, in _scrape
    parse_response = await self._parser.parse(self._browser, { "url": url } )
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/parser/parser.py", line 19, in parse
    context = await s.run(browser, context, pr)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/examples/main.py", line 63, in run
    await page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/dev/lib/python3.12/site-packages/playwright/async_api/_generated.py", line 11174, in wait_for_timeout
    await self._impl_obj.wait_for_timeout(timeout=timeout)
  File "/home/mk/code/goodreads_crawler/dev/lib/python3.12/site-packages/playwright/_impl/_page.py", line 1023, in wait_for_timeout
    await self._main_frame.wait_for_timeout(timeout)
  File "/home/mk/code/goodreads_crawler/dev/lib/python3.12/site-packages/playwright/_impl/_frame.py", line 758, in wait_for_timeout
    await self._channel.send("waitForTimeout", locals_to_params(locals()))
  File "/home/mk/code/goodreads_crawler/dev/lib/python3.12/site-packages/playwright/_impl/_connection.py", line 59, in send
    return await self._connection.wrap_api_call(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/dev/lib/python3.12/site-packages/playwright/_impl/_connection.py", line 514, in wrap_api_call
    raise rewrite_error(error, f"{parsed_st['apiName']}: {error}") from None
playwright._impl._errors.TargetClosedError: Page.wait_for_timeout: Target page, context or browser has been closed
07/16/2024 01:56:04 AM -- INFO  --  crawler.py:103 -- Starting URL scrapper.
07/16/2024 01:56:04 AM -- INFO  --  crawler.py:106 -- Fetching new URL from redis.
07/16/2024 01:56:04 AM -- INFO  --  crawler.py:122 -- Queued processing for URL: https://www.goodreads.com/book/show/26072627-red-queen-collection.
07/16/2024 01:56:06 AM -- ERROR  --  base_events.py:1821 -- Future exception was never retrieved
future: <Future finished exception=TargetClosedError('Target page, context or browser has been closed')>
playwright._impl._errors.TargetClosedError: Target page, context or browser has been closed
07/16/2024 01:56:12 AM -- INFO  --  crawler.py:103 -- Starting URL scrapper.
07/16/2024 01:56:12 AM -- INFO  --  crawler.py:106 -- Fetching new URL from redis.
07/16/2024 01:56:12 AM -- INFO  --  crawler.py:122 -- Queued processing for URL: https://www.goodreads.com/book/show/167055096-zawsze-chodzi-o-o-ciebie.
07/16/2024 01:56:54 AM -- INFO  --  crawler.py:103 -- Starting URL scrapper.
07/16/2024 01:56:54 AM -- INFO  --  crawler.py:106 -- Fetching new URL from redis.
07/16/2024 01:56:54 AM -- INFO  --  crawler.py:122 -- Queued processing for URL: https://www.goodreads.com/book/show/77203.The_Kite_Runner.
07/16/2024 01:57:09 AM -- INFO  --  crawler.py:122 -- Queued processing for URL: https://www.goodreads.com/book/show/1955205.The_Mum_Detective.
07/16/2024 01:57:19 AM -- INFO  --  crawler.py:122 -- Queued processing for URL: https://www.goodreads.com/book/show/34234631-mr-salary.
07/16/2024 01:57:34 AM -- INFO  --  crawler.py:122 -- Queued processing for URL: https://www.goodreads.com/book/show/198973495-smak-gorzkiej-czekolady.
07/16/2024 01:57:43 AM -- INFO  --  crawler.py:122 -- Queued processing for URL: https://www.goodreads.com/book/show/43554866-violet-bent-backwards-over-the-grass.
07/16/2024 01:57:54 AM -- INFO  --  crawler.py:122 -- Queued processing for URL: https://www.goodreads.com/book/show/128747007-emperor-of-rome.
07/16/2024 01:58:04 AM -- INFO  --  crawler.py:122 -- Queued processing for URL: https://www.goodreads.com/book/show/127547351-goldenseal.
07/16/2024 01:58:09 AM -- ERROR  --  base_events.py:1821 -- Future exception was never retrieved
future: <Future finished exception=TargetClosedError('Target page, context or browser has been closed')>
playwright._impl._errors.TargetClosedError: Target page, context or browser has been closed
07/16/2024 01:58:19 AM -- DEBUG  --  peewee.py:3319 -- ('CREATE TABLE IF NOT EXISTS "book" ("id" INTEGER NOT NULL PRIMARY KEY, "title" VARCHAR(255) NOT NULL, "author" VARCHAR(255) NOT NULL, "description" VARCHAR(255) NOT NULL, "genres" VARCHAR(255) NOT NULL, "imgUrl" VARCHAR(255) NOT NULL, "url" VARCHAR(255) NOT NULL)', [])
07/16/2024 01:58:19 AM -- DEBUG  --  selector_events.py:64 -- Using selector: EpollSelector
07/16/2024 01:58:19 AM -- INFO  --  crawler.py:103 -- Starting URL scrapper.
07/16/2024 01:58:19 AM -- INFO  --  crawler.py:106 -- Fetching new URL from redis.
07/16/2024 01:58:19 AM -- DEBUG  --  crawler.py:57 -- Looking for URL in set...
07/16/2024 01:58:19 AM -- DEBUG  --  crawler.py:74 -- Got URL https://www.goodreads.com/book/show/2151148.Balladyna
07/16/2024 01:58:19 AM -- DEBUG  --  crawler.py:75 -- Moved url to processing set.
07/16/2024 01:58:19 AM -- INFO  --  crawler.py:122 -- Queued processing for URL: https://www.goodreads.com/book/show/2151148.Balladyna.
07/16/2024 01:58:19 AM -- DEBUG  --  crawler.py:127 -- Sleeping for 14s before queuing next URL to rate-limit...
07/16/2024 01:58:33 AM -- DEBUG  --  crawler.py:57 -- Looking for URL in set...
07/16/2024 01:58:33 AM -- DEBUG  --  crawler.py:74 -- Got URL https://www.goodreads.com/book/show/123087784-the-comfort-of-crows
07/16/2024 01:58:33 AM -- DEBUG  --  crawler.py:75 -- Moved url to processing set.
07/16/2024 01:58:33 AM -- INFO  --  crawler.py:122 -- Queued processing for URL: https://www.goodreads.com/book/show/123087784-the-comfort-of-crows.
07/16/2024 01:58:33 AM -- DEBUG  --  crawler.py:127 -- Sleeping for 9s before queuing next URL to rate-limit...
07/16/2024 01:58:35 AM -- DEBUG  --  crawler.py:87 -- Finished parsing for https://www.goodreads.com/book/show/2151148.Balladyna:
 null
07/16/2024 01:58:35 AM -- DEBUG  --  crawler.py:88 -- Writing to storage.
07/16/2024 01:58:35 AM -- DEBUG  --  crawler.py:95 -- Moved https://www.goodreads.com/book/show/2151148.Balladyna to processed set.
07/16/2024 01:58:42 AM -- DEBUG  --  crawler.py:57 -- Looking for URL in set...
07/16/2024 01:58:42 AM -- DEBUG  --  crawler.py:74 -- Got URL https://www.goodreads.com/book/show/7905977-the-adventures-of-ook-and-gluk
07/16/2024 01:58:42 AM -- DEBUG  --  crawler.py:75 -- Moved url to processing set.
07/16/2024 01:58:42 AM -- INFO  --  crawler.py:122 -- Queued processing for URL: https://www.goodreads.com/book/show/7905977-the-adventures-of-ook-and-gluk.
07/16/2024 01:58:42 AM -- DEBUG  --  crawler.py:127 -- Sleeping for 14s before queuing next URL to rate-limit...
07/16/2024 01:58:48 AM -- ERROR  --  base_events.py:1821 -- Future exception was never retrieved
future: <Future finished exception=TargetClosedError('Target page, context or browser has been closed')>
playwright._impl._errors.TargetClosedError: Target page, context or browser has been closed
07/16/2024 01:59:46 AM -- DEBUG  --  peewee.py:3319 -- ('CREATE TABLE IF NOT EXISTS "book" ("id" INTEGER NOT NULL PRIMARY KEY, "title" VARCHAR(255) NOT NULL, "author" VARCHAR(255) NOT NULL, "description" VARCHAR(255) NOT NULL, "genres" VARCHAR(255) NOT NULL, "imgUrl" VARCHAR(255) NOT NULL, "url" VARCHAR(255) NOT NULL)', [])
07/16/2024 01:59:46 AM -- DEBUG  --  selector_events.py:64 -- Using selector: EpollSelector
07/16/2024 01:59:46 AM -- INFO  --  crawler.py:104 -- Starting URL scrapper.
07/16/2024 01:59:46 AM -- INFO  --  crawler.py:107 -- Fetching new URL from redis.
07/16/2024 01:59:46 AM -- DEBUG  --  crawler.py:58 -- Looking for URL in set...
07/16/2024 01:59:46 AM -- DEBUG  --  crawler.py:75 -- Got URL https://www.goodreads.com/book/show/75665925-mr-whiskers-and-the-shenanigan-sisters
07/16/2024 01:59:46 AM -- DEBUG  --  crawler.py:76 -- Moved url to processing set.
07/16/2024 01:59:46 AM -- INFO  --  crawler.py:123 -- Queued processing for URL: https://www.goodreads.com/book/show/75665925-mr-whiskers-and-the-shenanigan-sisters.
07/16/2024 01:59:46 AM -- DEBUG  --  crawler.py:128 -- Sleeping for 8s before queuing next URL to rate-limit...
07/16/2024 01:59:54 AM -- DEBUG  --  crawler.py:58 -- Looking for URL in set...
07/16/2024 01:59:54 AM -- DEBUG  --  crawler.py:75 -- Got URL https://www.goodreads.com/book/show/551866.I_and_Thou
07/16/2024 01:59:54 AM -- DEBUG  --  crawler.py:76 -- Moved url to processing set.
07/16/2024 01:59:54 AM -- INFO  --  crawler.py:123 -- Queued processing for URL: https://www.goodreads.com/book/show/551866.I_and_Thou.
07/16/2024 01:59:54 AM -- DEBUG  --  crawler.py:128 -- Sleeping for 14s before queuing next URL to rate-limit...
07/16/2024 02:00:08 AM -- DEBUG  --  crawler.py:58 -- Looking for URL in set...
07/16/2024 02:00:08 AM -- DEBUG  --  crawler.py:75 -- Got URL https://www.goodreads.com/book/show/177185877-the-underground-library
07/16/2024 02:00:08 AM -- DEBUG  --  crawler.py:76 -- Moved url to processing set.
07/16/2024 02:00:08 AM -- INFO  --  crawler.py:123 -- Queued processing for URL: https://www.goodreads.com/book/show/177185877-the-underground-library.
07/16/2024 02:00:08 AM -- DEBUG  --  crawler.py:128 -- Sleeping for 11s before queuing next URL to rate-limit...
07/16/2024 02:00:19 AM -- DEBUG  --  crawler.py:58 -- Looking for URL in set...
07/16/2024 02:00:19 AM -- DEBUG  --  crawler.py:75 -- Got URL https://www.goodreads.com/book/show/56860550-nellie-bly-dans-l-antre-de-la-folie
07/16/2024 02:00:19 AM -- DEBUG  --  crawler.py:76 -- Moved url to processing set.
07/16/2024 02:00:19 AM -- INFO  --  crawler.py:123 -- Queued processing for URL: https://www.goodreads.com/book/show/56860550-nellie-bly-dans-l-antre-de-la-folie.
07/16/2024 02:00:19 AM -- DEBUG  --  crawler.py:128 -- Sleeping for 11s before queuing next URL to rate-limit...
07/16/2024 02:00:30 AM -- DEBUG  --  crawler.py:58 -- Looking for URL in set...
07/16/2024 02:00:30 AM -- DEBUG  --  crawler.py:75 -- Got URL https://www.goodreads.com/book/show/60505465-agents-of-s-u-i-t
07/16/2024 02:00:30 AM -- DEBUG  --  crawler.py:76 -- Moved url to processing set.
07/16/2024 02:00:30 AM -- INFO  --  crawler.py:123 -- Queued processing for URL: https://www.goodreads.com/book/show/60505465-agents-of-s-u-i-t.
07/16/2024 02:00:30 AM -- DEBUG  --  crawler.py:128 -- Sleeping for 14s before queuing next URL to rate-limit...
07/16/2024 02:00:35 AM -- ERROR  --  base_events.py:1821 -- Task exception was never retrieved
future: <Task finished name='Task-75665925-mr-whiskers-and-the-shenanigan-sisters' coro=<Crawler.process_url() done, defined at /home/mk/code/goodreads_crawler/src/octo/core/crawler.py:84> exception=NameError("name 'BS' is not defined")>
Traceback (most recent call last):
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 86, in process_url
    info = parse_document(parse_response.html, self._parse_nodes)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/parser/utils.py", line 10, in parse_document
    soup = BS(html, "html.parser")
           ^^
NameError: name 'BS' is not defined
07/16/2024 02:00:35 AM -- ERROR  --  base_events.py:1821 -- Task exception was never retrieved
future: <Task finished name='Task-551866.I_and_Thou' coro=<Crawler.process_url() done, defined at /home/mk/code/goodreads_crawler/src/octo/core/crawler.py:84> exception=NameError("name 'BS' is not defined")>
Traceback (most recent call last):
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 86, in process_url
    info = parse_document(parse_response.html, self._parse_nodes)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/parser/utils.py", line 10, in parse_document
    soup = BS(html, "html.parser")
           ^^
NameError: name 'BS' is not defined
07/16/2024 02:00:35 AM -- ERROR  --  base_events.py:1821 -- Task exception was never retrieved
future: <Task finished name='Task-177185877-the-underground-library' coro=<Crawler.process_url() done, defined at /home/mk/code/goodreads_crawler/src/octo/core/crawler.py:84> exception=NameError("name 'BS' is not defined")>
Traceback (most recent call last):
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 86, in process_url
    info = parse_document(parse_response.html, self._parse_nodes)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/parser/utils.py", line 10, in parse_document
    soup = BS(html, "html.parser")
           ^^
NameError: name 'BS' is not defined
07/16/2024 02:00:35 AM -- ERROR  --  base_events.py:1821 -- Task exception was never retrieved
future: <Task finished name='Task-56860550-nellie-bly-dans-l-antre-de-la-folie' coro=<Crawler.process_url() done, defined at /home/mk/code/goodreads_crawler/src/octo/core/crawler.py:84> exception=NameError("name 'BS' is not defined")>
Traceback (most recent call last):
  File "/home/mk/code/goodreads_crawler/src/octo/core/crawler.py", line 86, in process_url
    info = parse_document(parse_response.html, self._parse_nodes)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mk/code/goodreads_crawler/src/octo/parser/utils.py", line 10, in parse_document
    soup = BS(html, "html.parser")
           ^^
NameError: name 'BS' is not defined
07/16/2024 02:01:18 AM -- DEBUG  --  peewee.py:3319 -- ('CREATE TABLE IF NOT EXISTS "book" ("id" INTEGER NOT NULL PRIMARY KEY, "title" VARCHAR(255) NOT NULL, "author" VARCHAR(255) NOT NULL, "description" VARCHAR(255) NOT NULL, "genres" VARCHAR(255) NOT NULL, "imgUrl" VARCHAR(255) NOT NULL, "url" VARCHAR(255) NOT NULL)', [])
07/16/2024 02:01:18 AM -- DEBUG  --  selector_events.py:64 -- Using selector: EpollSelector
07/16/2024 02:01:19 AM -- INFO  --  crawler.py:104 -- Starting URL scrapper.
07/16/2024 02:01:19 AM -- INFO  --  crawler.py:107 -- Fetching new URL from redis.
07/16/2024 02:01:19 AM -- DEBUG  --  crawler.py:58 -- Looking for URL in set...
07/16/2024 02:01:19 AM -- DEBUG  --  crawler.py:75 -- Got URL https://www.goodreads.com/book/show/484436.Drau_en_vor_der_T_r
07/16/2024 02:01:19 AM -- DEBUG  --  crawler.py:76 -- Moved url to processing set.
07/16/2024 02:01:19 AM -- INFO  --  crawler.py:123 -- Queued processing for URL: https://www.goodreads.com/book/show/484436.Drau_en_vor_der_T_r.
07/16/2024 02:01:19 AM -- DEBUG  --  crawler.py:128 -- Sleeping for 12s before queuing next URL to rate-limit...
07/16/2024 02:01:31 AM -- DEBUG  --  crawler.py:58 -- Looking for URL in set...
07/16/2024 02:01:31 AM -- DEBUG  --  crawler.py:75 -- Got URL https://www.goodreads.com/book/show/60784605-maame
07/16/2024 02:01:31 AM -- DEBUG  --  crawler.py:76 -- Moved url to processing set.
07/16/2024 02:01:31 AM -- INFO  --  crawler.py:123 -- Queued processing for URL: https://www.goodreads.com/book/show/60784605-maame.
07/16/2024 02:01:31 AM -- DEBUG  --  crawler.py:128 -- Sleeping for 10s before queuing next URL to rate-limit...
07/16/2024 02:01:35 AM -- DEBUG  --  crawler.py:88 -- Finished parsing for https://www.goodreads.com/book/show/484436.Drau_en_vor_der_T_r:
 {
  "title": "Drau\u00dfen vor der T\u00fcr",
  "imgUrl": "https://images-na.ssl-images-amazon.com/images/S/compressed.photo.goodreads.com/books/1412606809i/484436.jpg",
  "author": "Wolfgang Borchert",
  "description": "Das einzige Drama des fr\u00fch verstorbenen Dichters ist ein verzweifelter Protestschrei gegen die zerst\u00f6rerische und verderbnistr\u00e4chtige Macht des Krieges. Seine Erz\u00e4hlungen und Prosast\u00fccke berichten mit sicher akzentuierter Ausdruckskraft von den verheerenden Kriegsfolgen im einzelnen und im gemeinsamen Menschenleben.",
  "genres": [
    "Classics",
    "German Literature",
    "Plays",
    "Fiction",
    "Drama",
    "Germany",
    "School"
  ]
}
07/16/2024 02:01:35 AM -- DEBUG  --  crawler.py:89 -- Writing to storage.
07/16/2024 02:01:35 AM -- DEBUG  --  crawler.py:96 -- Moved https://www.goodreads.com/book/show/484436.Drau_en_vor_der_T_r to processed set.
07/16/2024 02:01:41 AM -- DEBUG  --  crawler.py:58 -- Looking for URL in set...
07/16/2024 02:01:41 AM -- DEBUG  --  crawler.py:75 -- Got URL https://www.goodreads.com/book/show/111673432-call-me-iggy
07/16/2024 02:01:41 AM -- DEBUG  --  crawler.py:76 -- Moved url to processing set.
07/16/2024 02:01:41 AM -- INFO  --  crawler.py:123 -- Queued processing for URL: https://www.goodreads.com/book/show/111673432-call-me-iggy.
07/16/2024 02:01:41 AM -- DEBUG  --  crawler.py:128 -- Sleeping for 8s before queuing next URL to rate-limit...
07/16/2024 02:01:46 AM -- DEBUG  --  crawler.py:88 -- Finished parsing for https://www.goodreads.com/book/show/60784605-maame:
 {
  "title": "Maame",
  "imgUrl": "https://images-na.ssl-images-amazon.com/images/S/compressed.photo.goodreads.com/books/1666031380i/60784605.jpg",
  "author": "Jessica George",
  "description": "Shortlisted for the TikTok Book Awards in the Book of the Year, 2023 and the Goodreads Debut and Fiction Book of the Year, 2023.It\u2019s fair to say that Maddie\u2019s life in London is far from rewarding. With a mother who spends most of her time in Ghana (yet still somehow manages to be overbearing), Maddie is the primary caretaker for her father, who suffers from advanced stage Parkinson\u2019s. At work, her boss is a nightmare and Maddie is tired of always being the only Black person in every meeting.When her mum returns from her latest trip to Ghana, Maddie leaps at the chance to get out of the family home and finally start living. A self-acknowledged late bloomer, she\u2019s ready to experience some important \u201cfirsts\u201d: She finds a flat share, says yes to after-work drinks, pushes for more recognition in her career, and throws herself into the bewildering world of internet dating. But it's not long before tragedy strikes, forcing Maddie to face the true nature of her unconventional family, and the perils\u2014and rewards\u2014of putting her life on the line.Smart, funny, and deeply affecting, Jessica George's Maame deals with the themes of our time with humor and poignancy: from familial duty and racism, to female pleasure, the complexity of love, and the life-saving power of friendship. Most important, it explores what it feels like to be torn between two homes and cultures\u2015and it celebrates finally being able to find where you belong.",
  "genres": [
    "Fiction",
    "Contemporary",
    "Audiobook",
    "Literary Fiction",
    "Coming Of Age",
    "Adult",
    "Family"
  ]
}
07/16/2024 02:01:46 AM -- DEBUG  --  crawler.py:89 -- Writing to storage.
07/16/2024 02:01:46 AM -- DEBUG  --  crawler.py:96 -- Moved https://www.goodreads.com/book/show/60784605-maame to processed set.
07/16/2024 02:01:49 AM -- DEBUG  --  crawler.py:58 -- Looking for URL in set...
07/16/2024 02:01:49 AM -- DEBUG  --  crawler.py:75 -- Got URL https://www.goodreads.com/book/show/181552767-au-chant-des-grenouilles---tome-1
07/16/2024 02:01:49 AM -- DEBUG  --  crawler.py:76 -- Moved url to processing set.
07/16/2024 02:01:49 AM -- INFO  --  crawler.py:123 -- Queued processing for URL: https://www.goodreads.com/book/show/181552767-au-chant-des-grenouilles---tome-1.
07/16/2024 02:01:49 AM -- DEBUG  --  crawler.py:128 -- Sleeping for 15s before queuing next URL to rate-limit...
07/16/2024 02:01:53 AM -- DEBUG  --  crawler.py:88 -- Finished parsing for https://www.goodreads.com/book/show/111673432-call-me-iggy:
 {
  "title": "Call Me Iggy",
  "imgUrl": "https://images-na.ssl-images-amazon.com/images/S/compressed.photo.goodreads.com/books/1683578175i/111673432.jpg",
  "author": "Jorge Aguirre",
  "description": "Ignacio \"Iggy\" Garcia is an Ohio-born Colombian American teen living his best life. After bumping into Marisol (and her coffee) at school, Iggy's world is spun around. But Marisol as too much going on to be bothered with the likes of Iggy. She has school, work, family, and the uphill battle of getting her legal papers. As Iggy stresses over how to get Marisol to like him, his grandfather comes to the rescue. The thing is, not only is his abuelito dead, but he also gives terrible love advice. The worst. And so, with his ghost abuelito's meddling, Iggy's life begins to unravel as he sets off on a journey of self-discovery.Call me Iggy tells the story of Iggy searching for his place in his family, his school, his community, and ultimately\u2014as the political climate in America changes during the 2016 election\u2014 his country. Focusing on familial ties and budding love, Call me Iggy challenges our assumptions about Latino-American identity while reaffirming our belief in the hope that all young people represent. Perfect for lovers of multigenerational stories like Displacement and The Magic Fish.",
  "genres": [
    "Graphic Novels",
    "Young Adult",
    "Romance",
    "Comics",
    "Middle Grade",
    "Ghosts",
    "Fiction"
  ]
}
07/16/2024 02:01:53 AM -- DEBUG  --  crawler.py:89 -- Writing to storage.
07/16/2024 02:01:53 AM -- DEBUG  --  crawler.py:96 -- Moved https://www.goodreads.com/book/show/111673432-call-me-iggy to processed set.
07/16/2024 02:01:58 AM -- DEBUG  --  crawler.py:88 -- Finished parsing for https://www.goodreads.com/book/show/181552767-au-chant-des-grenouilles---tome-1:
 {
  "title": "Au chant des grenouilles - Tome 1: Urania, la sorci\u00e8re",
  "imgUrl": "https://images-na.ssl-images-amazon.com/images/S/compressed.photo.goodreads.com/books/1706520353i/181552767.jpg",
  "author": "Barbara Canepa",
  "description": "CETTE S\u00c9RIE-CONCEPT JEUNESSE, CR\u00c9\u00c9E PAR BARBARA CANEPA, COSCENARIS\u00c9E AVEC ANA\u00cfS HALARD ET DONT CHAQUE TOME EST DESSINE PAR UN AUTEUR DIFF\u00c9RENT, \u00c9VOLUERA SELON UN RYTHME DE PARUTION SEMESTRIEL. L'univers graphique du premier opus est cr\u00e9\u00e9 par le tr\u00e8s talentueux Florent Sacr\u00e9, ex-directeur artistique d'Ubisoft \u00e0 l'origine de jeux vid\u00e9o aussi c\u00e9l\u00e8bres qu'\u00ab Assassin's Creed \u00bb, \u00ab Les Lapins cr\u00e9tins \u00bb, ou encore \u00ab Rayman \u00bb... \u00ab Au chant des grenouilles \u00bb invite petits et grands, en qu\u00eate de rep\u00e8res, au c\u0153ur d'un univers anthropomorphique, afin de leur faire d\u00e9couvrir la lecture enchanteresse des signes et des secrets qu'offre la nature. Sous la forme d'histoires en BD mettant en sc\u00e8ne les aventures de plusieurs familles d'animaux, entrecoup\u00e9es par des pages p\u00e9dagogiques illustr\u00e9es par Giovanni Rigano, \u00ab Au chant des grenouilles \u00bb s'annonce comme une s\u00e9rie r\u00e9solument ludique, \u00e9cologique et didactique.",
  "genres": [
    "Bande Dessin\u00e9e",
    "Graphic Novels",
    "Fantasy",
    "Comics"
  ]
}
07/16/2024 02:01:58 AM -- DEBUG  --  crawler.py:89 -- Writing to storage.
07/16/2024 02:01:58 AM -- DEBUG  --  crawler.py:96 -- Moved https://www.goodreads.com/book/show/181552767-au-chant-des-grenouilles---tome-1 to processed set.
07/16/2024 02:02:04 AM -- DEBUG  --  crawler.py:58 -- Looking for URL in set...
07/16/2024 02:02:04 AM -- DEBUG  --  crawler.py:75 -- Got URL https://www.goodreads.com/book/show/41734205-her-royal-highness
07/16/2024 02:02:04 AM -- DEBUG  --  crawler.py:76 -- Moved url to processing set.
07/16/2024 02:02:04 AM -- INFO  --  crawler.py:123 -- Queued processing for URL: https://www.goodreads.com/book/show/41734205-her-royal-highness.
07/16/2024 02:02:04 AM -- DEBUG  --  crawler.py:128 -- Sleeping for 13s before queuing next URL to rate-limit...
07/16/2024 02:02:09 AM -- ERROR  --  base_events.py:1821 -- Future exception was never retrieved
future: <Future finished exception=TargetClosedError('Target page, context or browser has been closed')>
playwright._impl._errors.TargetClosedError: Target page, context or browser has been closed
